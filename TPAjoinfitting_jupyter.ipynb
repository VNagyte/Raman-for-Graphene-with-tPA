{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "##################### IMPORTING REQUIRED MODULES ###################\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "import rampy as rp\n",
    "import pylab as plb\n",
    "from matplotlib import gridspec\n",
    "import fnmatch\n",
    "import lmfit\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########################## SET PARAMETERS ############################\n",
    "\n",
    "file_baseg = 'g'\n",
    "file_base2d = '2d'\n",
    "file_base = 'flake'\n",
    "file_suffix = '.txt'\n",
    "fig_suffix = '.png'\n",
    "\n",
    "\n",
    "first_file = 0\n",
    "numberoffiles = len(fnmatch.filter(os.listdir('.'), file_baseg+'*'+file_suffix))\n",
    "\n",
    "#this ratio scales intensities of G and 2D peaks\n",
    "ratio = 2 #change this to 1 if your measurements are the same length and accumulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "######################### DEFINING FUNCTIONS #######################\n",
    "\n",
    "def lorentzian(x, a, f, l, y0=0): # [hwhm, peak center, intensity, y0] #\n",
    "    numerator =  (0.5*l)**2\n",
    "    denominator = ( x - (f) )**2 + (0.5*l)**2\n",
    "    y = a*(numerator/denominator)+y0\n",
    "    return y\n",
    "\n",
    "\n",
    "def residual4(pars, x, data=None, eps=None):\n",
    "    # unpack parameters:\n",
    "    #  extract .value attribute for each parameter\n",
    "    # a - amplitude; f - freaquency, l - FWHM?\n",
    "    a1 = pars['a1'].value\n",
    "    a2 = pars['a2'].value\n",
    "    a3 = pars['a3'].value\n",
    "    a4 = pars['a4'].value\n",
    "\n",
    "    \n",
    "    f1 = pars['f1'].value\n",
    "    f2 = pars['f2'].value\n",
    "    f3 = pars['f3'].value\n",
    "    f4 = pars['f4'].value\n",
    "    \n",
    "    \n",
    "    l1 = pars['l1'].value\n",
    "    l2 = pars['l2'].value\n",
    "    l3 = pars['l3'].value\n",
    "    l4 = pars['l4'].value\n",
    "\n",
    "    \n",
    "    # lorentzian model\n",
    "    \n",
    "    peak1 = lorentzian(x,a1,f1,l1)\n",
    "    peak2 = lorentzian(x,a2,f2,l2)\n",
    "    peak3 = lorentzian(x,a3,f3,l3)\n",
    "    peak4 = lorentzian(x,a4,f4,l4)\n",
    "  \n",
    "    \n",
    "    model = peak1 + peak2 + peak3 + peak4\n",
    "    \n",
    "    if data is None:\n",
    "        return model, peak1, peak2, peak3, peak4\n",
    "    if eps is None:\n",
    "        return (model - data)\n",
    "    return (model - data)/eps\n",
    "\n",
    "\n",
    "def residual2(pars, x, data=None, eps=None):\n",
    "    # unpack parameters:\n",
    "    #  extract .value attribute for each parameter\n",
    "    # a - amplitude; f - freaquency, l - FWHM?\n",
    "    a1 = pars['a1'].value\n",
    "    a2 = pars['a2'].value\n",
    "        \n",
    "    f1 = pars['f1'].value\n",
    "    f2 = pars['f2'].value\n",
    "   \n",
    "    l1 = pars['l1'].value\n",
    "    l2 = pars['l2'].value\n",
    "\n",
    "    \n",
    "    # lorentzian model\n",
    "    \n",
    "    peak1 = lorentzian(x,a1,f1,l1)\n",
    "    peak2 = lorentzian(x,a2,f2,l2)\n",
    "  \n",
    "    \n",
    "    model = peak1 + peak2\n",
    "    \n",
    "    if data is None:\n",
    "        return model, peak1, peak2\n",
    "    if eps is None:\n",
    "        return (model - data)\n",
    "    return (model - data)/eps\n",
    "\n",
    "def residual1(pars, x, data=None, eps=None):\n",
    "    # unpack parameters:\n",
    "    #  extract .value attribute for each parameter\n",
    "    # a - amplitude; f - freaquency, l - FWHM?\n",
    "    a1 = pars['a1'].value        \n",
    "    f1 = pars['f1'].value   \n",
    "    l1 = pars['l1'].value\n",
    "    \n",
    "    # lorentzian model\n",
    "    \n",
    "    peak1 = lorentzian(x,a1,f1,l1) \n",
    "    \n",
    "    model = peak1\n",
    "    \n",
    "    if data is None:\n",
    "        return model, peak1\n",
    "    if eps is None:\n",
    "        return (model - data)\n",
    "    return (model - data)/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n",
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n",
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n",
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n",
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n",
      "/home/vaiva/.local/lib/python3.6/site-packages/rampy/baseline.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  wt = 1.0/(1 + np.exp( 2* (d-(2*s-m))/s ) )\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "########################## LOADING DATA ############################\n",
    "#initial arrays\n",
    "allinall=[]\n",
    "\n",
    "for e in range(first_file, numberoffiles):\n",
    "\n",
    "    # generate corresponding full file name\n",
    "    full_fnameg = file_baseg + str(e) + file_suffix\n",
    "    full_fname2d = file_base2d + str(e) + file_suffix\n",
    "\n",
    "    if not (os.path.exists(full_fnameg) and os.path.exists(full_fname2d)):\n",
    "        print (\"no such file %s \" % full_fnameg, full_fname2d)\n",
    "        e =+ 1\n",
    "    else:\n",
    "        # read that file into an array\n",
    "        filedatag = np.genfromtxt(full_fnameg, comments='#', delimiter='\\t')\n",
    "        filedata2d = np.genfromtxt(full_fname2d, comments='#', delimiter='\\t')\n",
    "\n",
    "\n",
    "        ####################################################################\n",
    "        ########################## D, G, 2D peak fitting ############################\n",
    "\n",
    "        #load data\n",
    "        xg = filedatag[:,0]\n",
    "        yg_org = filedatag[:,1]\n",
    "        x2d = filedata2d[:,0]\n",
    "        y2d_org = filedata2d[:,1]/ratio\n",
    "        \n",
    "        #smooth\n",
    "        yg_s = rp.smooth(xg,yg_org,method=\"whittaker\",Lambda=10)\n",
    "        y2d_s = rp.smooth(x2d,y2d_org,method=\"whittaker\",Lambda=10)        \n",
    "        \n",
    "        #remove background\n",
    "            #g peak\n",
    "        bir = np.array([(min(xg),1030),(1900,max(xg))])\n",
    "        yg_cor, background = rp.baseline(xg,yg_s,bir,\"arPLS\",lam=10**8)\n",
    "        yg_corr = yg_cor[:,0]\n",
    "        \n",
    "            #2d peak\n",
    "        bir = np.array([(min(x2d),2550),(3100,max(x2d))])\n",
    "        y2d_cor, background = rp.baseline(x2d,y2d_s,bir,\"arPLS\",lam=10**8)\n",
    "        y2d_corr = y2d_cor[:,0]        \n",
    "        \n",
    "        #fix spectrum\n",
    "        y = np.concatenate((y2d_corr,yg_corr))\n",
    "        x = np.concatenate((x2d,xg))\n",
    "        \n",
    "                \n",
    "        bir = np.array([(min(x),1050.),(1880.,2300.), (2400.,2500),(3050.,max(x))])\n",
    "        yg_corrected, background = rp.baseline(x,y,bir,\"arPLS\",lam=10**8)\n",
    "        y = yg_corrected[:,0]\n",
    "              \n",
    "        #normalise\n",
    "        yg = rp.normalise(yg_corr,method=\"minmax\")\n",
    "        y2d = rp.normalise(y2d_corr,method=\"minmax\")\n",
    "        y = rp.normalise(y,method=\"minmax\")\n",
    "        \n",
    "        \n",
    "        ##fitting t-PA##\n",
    "\n",
    "        # signal selection\n",
    "        x_fit = xg[np.where((xg > 1050)&(xg < 1250))]\n",
    "        y_fit = yg_org[np.where((xg > 1050)&(xg < 1250))]\n",
    "        \n",
    "        #signal processing\n",
    "        bir = np.array([(1050., 1190)])\n",
    "        y_fit, background = rp.baseline(x_fit,y_fit,bir,\"poly\",poly=1)\n",
    "        \n",
    "        y_fit = rp.smooth(x_fit,y_fit[:,0],method=\"whittaker\",Lambda=10)\n",
    "        y_fit = rp.normalise(y_fit,method=\"minmax\")\n",
    "\n",
    "        params = lmfit.Parameters()\n",
    "#               (Name,  Value,  Vary,   Min,  Max,  Expr)\n",
    "        params.add_many(('a1',   0.3,   True,  0,      1,  None),\n",
    "                        ('f1',   1135,   True, 1100,   1150,  None),\n",
    "                        ('l1',   40,   True,  20,      80,  None))\n",
    "\n",
    "        result = lmfit.minimize(residual1, params, method ='least_squares', args=(x_fit, y_fit)) \n",
    "\n",
    "        model = lmfit.fit_report(result.params)\n",
    "        yout, peak1 = residual1(result.params,x_fit)\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(y_fit, yout)\n",
    "        r_tpa = r_value**2\n",
    "        \n",
    "        \n",
    "        #g peak fitting\n",
    "        \n",
    "        if (result.params['a1'].value >= 0.55) and (r_tpa >= 0.25):\n",
    "            params = lmfit.Parameters()\n",
    "    #               (Name,  Value,  Vary,   Min,  Max,  Expr)\n",
    "            params.add_many(('a1',   0.5,   True,  0,      1,  None),\n",
    "                            ('f1',   1350,   True, 1330,   1370,  None),\n",
    "                            ('l1',   40,   True,  0,      150,  None),\n",
    "                            ('a2',  1,   True,  0.3,     1,  None),\n",
    "                            ('f2',   1580,   True, 1550,   1600,  None),\n",
    "                            ('l2',   20,   True,  0,   80,  None),\n",
    "                            ('a3',   None,   True,  0,     0.6,  'a1/4'),\n",
    "                            ('f3',   None,   True,  None,     None,  'f1+270'),\n",
    "                            ('l3',   None,   True,  None,     None,  'l1*0.25'),\n",
    "                            ('a4',  0.3,   True,  0,   0.7,  None),\n",
    "                            ('f4',   1530,   True,  1505, 1560,  None),\n",
    "                            ('l4',   50,   True,  20,     80,  None))\n",
    "\n",
    "            result = lmfit.minimize(residual4, params, method = 'least_squares', args=(xg, yg))         \n",
    "            modelg = lmfit.fit_report(result.params)\n",
    "            youtg, peakg1,peakg2, peakg3, peakg4 = residual4(result.params,xg) # the different peaks\n",
    "\n",
    "            #save results in a list\n",
    "            best_para = [e, 'tpa']\n",
    "            for name in result.params.valuesdict():\n",
    "                best_para=best_para+[result.params[name].value]\n",
    "                \n",
    "        else:\n",
    "            params = lmfit.Parameters()\n",
    "    #               (Name,  Value,  Vary,   Min,  Max,  Expr)\n",
    "            params.add_many(('a1',   0.5,   True,  0,      1,  None),\n",
    "                            ('f1',   1350,   True, 1330,   1370,  None),\n",
    "                            ('l1',   40,   True,  0,      150,  None),\n",
    "                            ('a2',  1,   True,  0.3,     1,  None),\n",
    "                            ('f2',   1580,   True, 1550,   1600,  None),\n",
    "                            ('l2',   20,   True,  0,   80,  None),\n",
    "                            ('a3',   None,   True,  0,     0.6,  'a1/4'),\n",
    "                            ('f3',   None,   True,  None,     None,  'f1+270'),\n",
    "                            ('l3',   None,   True,  None,     None,  'l1*0.25'),\n",
    "                            ('a4',  0,   None,  None,   None,  None),\n",
    "                            ('f4',  0,   None,  None,   None,  None),\n",
    "                            ('l4',   0,   None,  None,   None,  None))\n",
    "\n",
    "            result = lmfit.minimize(residual4, params, method = 'least_squares', args=(xg, yg))         \n",
    "            modelg = lmfit.fit_report(result.params)\n",
    "            youtg, peakg1,peakg2, peakg3, peakg4 = residual4(result.params,xg) # the different peaks\n",
    "\n",
    "            #save results in a list\n",
    "            best_para = [e, 'defected']\n",
    "            for name in result.params.valuesdict():\n",
    "                best_para=best_para+[result.params[name].value]\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #2D peak fitting\n",
    "        params = lmfit.Parameters()\n",
    "#               (Name,  Value,  Vary,   Min,  Max,  Expr)\n",
    "        params.add_many(('a1',  0.5,   True,  0,     1,  None),\n",
    "                        ('f1',   2690,   True, 2650,   2720,  None),\n",
    "                        ('l1',   50,   True,  0,   180,  None),\n",
    "                        ('a2',  0.2,   True,  0,     1,  None),\n",
    "                        ('f2',   2940,   True, 2900,   3100,  None),\n",
    "                        ('l2',   40,   True,  0,   180,  None))\n",
    "\n",
    "        result = lmfit.minimize(residual2, params, method = 'leastsq', args=(x2d, y2d))         \n",
    "        model2d = lmfit.fit_report(result.params)\n",
    "        yout2d, peak2d1,peak2d2 = residual2(result.params,x2d) # the different peaks\n",
    "\n",
    "        #save results in a list\n",
    "        for name in result.params.valuesdict():\n",
    "            best_para=best_para+[result.params[name].value]\n",
    "\n",
    "\n",
    "# #         ############################## PLOTTING FULL RAMAN ############################\n",
    "        fig = plb.figure(figsize=(12, 6)) \n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])\n",
    "\n",
    "        ax0 = plb.subplot(gs[0])\n",
    "        ax0.plot(xg, yg,'k', xg, youtg, 'r--', xg, peakg2, 'g:',xg, peakg3, 'g:', xg, peakg1, 'g:',  xg, peakg4, 'g:')\n",
    "        plb.title('G and D peaks of flake %1.0f' %e, loc='right')\n",
    "        ax0.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "        plb.xlabel(r'$\\omega$ (cm$^{-1}$)', fontsize=10)\n",
    "        plb.ylabel('Intensity (arb.units)', fontsize=10)\n",
    "        ax0.grid(True, which='major', ls='-', alpha=0.1)\n",
    "\n",
    "        ax1 = plb.subplot(gs[1])\n",
    "        ax1.plot(x2d, y2d,'k', x2d, yout2d, 'r--', x2d, peak2d1, 'g:', x2d, peak2d2, 'g:')\n",
    "        plb.title(\"2D and D\\'+D peaks of flake %1.0f\" %e, loc='right')\n",
    "        ax1.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "        plb.xlabel(r'$\\omega$ (cm$^{-1}$)', fontsize=10) \n",
    "        plb.ylabel('Intensity (arb.units)', fontsize=10)\n",
    "        ax1.grid(True, which='major', ls='-', alpha=0.1)\n",
    "\n",
    "        # save the figure to file\n",
    "        plb.tight_layout()\n",
    "        plb.savefig(file_base + str(e) + fig_suffix, format='png', dpi=300)\n",
    "        #plb.show(block=False)  ## show plot ##\n",
    "        plb.close()\n",
    "\n",
    "\n",
    "        #merging fitting parameters\n",
    "        allinall.append(best_para) #get values and sandart derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ####################################################################\n",
    "        ############################## SAVING FILES ###########################\n",
    "\n",
    "        #saving normalised spectra\n",
    "        spectrum = np.array((x, y)).T\n",
    "        np.savetxt('spectrum'+str(e)+file_suffix, spectrum,fmt='%f', delimiter='\\t', newline='\\n') #\n",
    "\n",
    "\n",
    "np.savetxt('allinall_tpa.csv', allinall, fmt = '%s', delimiter=',', newline='\\n', \n",
    "           header = 'Flake,status,D_Intensity,D_Position,D_FWHM,G_Intensity,'+\n",
    "           'G_Position,G_FWHM,D\\'_Intensity,D\\'_Position,'+\n",
    "           'D\\'_FWHM,tpa_Intensity,tpa_Position,tpa_FWHM,2D_Intensity,'+\n",
    "           '2D_Position,2D_FWHM,2D\\'_Intensity,2D\\'_Position,2D\\'_FWHM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
